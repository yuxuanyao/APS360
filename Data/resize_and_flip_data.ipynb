{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "training = pd.read_csv('./training.csv', usecols=[\"emotion\", \"image\",\" pixels\"])\n",
    "validation = pd.read_csv('./validation.csv', usecols=[\"emotion\", \"image\",\" pixels\"])\n",
    "test = pd.read_csv('./test.csv', usecols=[\"emotion\", \"image\",\" pixels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from os import path\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt # for debugging\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\"\"\"\n",
    "Transforms the imgs in the training/testing/validation dataset and saves them as tensors\n",
    "\n",
    "Arguments:\n",
    "dataset: 'train', 'test', or 'validate'\n",
    "num_imgs: number of imgs/pixels in the csv dataset\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def resize_and_flip(dataset, num_imgs):\n",
    "    \n",
    "    if dataset=='test':\n",
    "        df = test\n",
    "    elif dataset=='validate':\n",
    "        df = validation\n",
    "    elif dataset=='train':\n",
    "        df = training\n",
    "    else:\n",
    "        print(\"ERR: dataset input is incorrect\")\n",
    "        return False\n",
    "    \n",
    "    for i in range(0, num_imgs):\n",
    "        img_pixels = df.iloc[i][\" pixels\"]\n",
    "        \n",
    "        # if images are jpg \n",
    "        if type(img_pixels) is float:\n",
    "            imgpath = './MuxspaceDataset/images/'\n",
    "            img_pixels = image.imread(imgpath + str(df.iloc[i][\"image\"]))   # load image as pixel array\n",
    "            img_data = np.resize(img_pixels, (48,48))\n",
    "            img_tensor = torch.from_numpy(img_data)\n",
    "            img_tensor_flipped = torch.from_numpy(np.fliplr(img_data).copy())\n",
    "           \n",
    "        # if images are pixels\n",
    "        else:\n",
    "            img_pixels = df.iloc[i][\" pixels\"]\n",
    "            img_string = img_pixels.split(' ')\n",
    "            img_data = np.asarray(img_string, dtype=np.uint8).reshape(48, 48)\n",
    "            img_tensor = torch.from_numpy(img_data)\n",
    "            img_tensor_flipped = torch.from_numpy(np.fliplr(img_data).copy())\n",
    "        \n",
    "        # save resized img as tensor\n",
    "        master_path = './ProcessedData/' + str(dataset) + '/'\n",
    "        folder_name = master_path + str(df.iloc[i][\"emotion\"])\n",
    "        if not os.path.isdir(folder_name):\n",
    "            os.mkdir(folder_name)\n",
    "        torch.save(img_tensor, folder_name + '/' + str(i) + '.tensor')\n",
    "        \n",
    "        # save flipped and resized img as tensor\n",
    "        torch.save(img_tensor_flipped, folder_name + '/' + str(num_imgs+i) + '.tensor')\n",
    "        \n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resize_and_flip(dataset='train', num_imgs=3696)\n",
    "resize_and_flip(dataset='validate', num_imgs=791)\n",
    "resize_and_flip(dataset='test', num_imgs=798)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 48, 48])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example of using dataloader on test images\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import torchvision\n",
    "\n",
    "# Load Tensor Files (tensors) from folder\n",
    "\n",
    "#load tensors\n",
    "master_path = './ProcessedData/test/'\n",
    "dataset = torchvision.datasets.DatasetFolder(master_path, loader=torch.load, extensions=('.tensor'))\n",
    "\n",
    "# Prepare Dataloader\n",
    "batch_size = 32\n",
    "num_workers = 1\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           num_workers=num_workers, shuffle=True)\n",
    "\n",
    "# Verification Step - obtain one batch of imgs\n",
    "dataiter = iter(test_loader)\n",
    "img, labels = dataiter.next()\n",
    "print(img.shape)\n",
    "print(labels.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
